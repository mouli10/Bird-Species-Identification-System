{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-14T14:30:24.912325Z",
     "iopub.status.busy": "2023-01-14T14:30:24.911932Z",
     "iopub.status.idle": "2023-01-14T14:30:26.939078Z",
     "shell.execute_reply": "2023-01-14T14:30:26.938134Z",
     "shell.execute_reply.started": "2023-01-14T14:30:24.912245Z"
    },
    "id": "kMqmcf_ZXNpi",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision.transforms as T\n",
    "from torchvision.utils import make_grid\n",
    "from PIL import Image\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6Y0I_V-ZEKe"
   },
   "source": [
    "Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-14T14:30:26.941924Z",
     "iopub.status.busy": "2023-01-14T14:30:26.941116Z",
     "iopub.status.idle": "2023-01-14T14:30:27.156365Z",
     "shell.execute_reply": "2023-01-14T14:30:27.155375Z",
     "shell.execute_reply.started": "2023-01-14T14:30:26.941888Z"
    },
    "id": "AR8qa5YgXNpm",
    "outputId": "6e03b191-8c16-4f62-f149-6478e06e3d34",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_dir = './100-bird-species'\n",
    "paths_df = pd.read_csv(os.path.join(data_dir, \"birds.csv\"))\n",
    "# The dataset as of 9-Jan-2023 contains a file that is \n",
    "# present at the given index whose dimension is not 224x224. Removing the file to avoid unnecessary complexity in the code\n",
    "paths_df.drop(40464, axis= 0, inplace=True)\n",
    "paths_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-14T14:30:27.158393Z",
     "iopub.status.busy": "2023-01-14T14:30:27.158043Z",
     "iopub.status.idle": "2023-01-14T14:30:27.193217Z",
     "shell.execute_reply": "2023-01-14T14:30:27.191757Z",
     "shell.execute_reply.started": "2023-01-14T14:30:27.158365Z"
    },
    "id": "TUd2rU5nXNpn",
    "outputId": "d7fd2e56-9bf0-4b97-d94f-a54a01c1fd2e",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "paths_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-7_585GZlH-"
   },
   "source": [
    "## Preparing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CXdQSzWMZmQx"
   },
   "source": [
    "Collecting the labels and mapping the labels to the birds name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-14T14:30:27.195284Z",
     "iopub.status.busy": "2023-01-14T14:30:27.194888Z",
     "iopub.status.idle": "2023-01-14T14:30:27.402055Z",
     "shell.execute_reply": "2023-01-14T14:30:27.401171Z",
     "shell.execute_reply.started": "2023-01-14T14:30:27.195247Z"
    },
    "id": "INIHbtaWXNpo",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# unique() function finds the unique elements\n",
    "#of an array and returns these unique elements as a sorted array.\n",
    "labels = paths_df[\"class id\"].unique()\n",
    "bird_name_map = {int(i): paths_df[paths_df[\"class id\"] == i][\"labels\"].values[0] for i in labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-14T14:30:27.405398Z",
     "iopub.status.busy": "2023-01-14T14:30:27.405076Z",
     "iopub.status.idle": "2023-01-14T14:30:27.410915Z",
     "shell.execute_reply": "2023-01-14T14:30:27.409758Z",
     "shell.execute_reply.started": "2023-01-14T14:30:27.405373Z"
    },
    "id": "Nr9SQpO7XNpo",
    "outputId": "2181ad3e-31d8-49cb-8153-729b68a35a79",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(labels)\n",
    "print(bird_name_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QG-v9qT-XNps"
   },
   "source": [
    "Plots 20 different random images from the dataset every time it runs from any of the 450 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-14T14:30:27.665045Z",
     "iopub.status.busy": "2023-01-14T14:30:27.664352Z",
     "iopub.status.idle": "2023-01-14T14:30:27.672286Z",
     "shell.execute_reply": "2023-01-14T14:30:27.671214Z",
     "shell.execute_reply.started": "2023-01-14T14:30:27.665009Z"
    },
    "id": "zpUbbn0dXNps",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "classes = os.listdir(data_dir + \"/train\")\n",
    "\n",
    "def show_images(dataset='train'):\n",
    "    # Parameters for our graph; we'll output images in a 5x4 configuration\n",
    "    nrows = 5\n",
    "    ncols = 4\n",
    "\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(ncols * 5, nrows * 5)\n",
    "    for i in range(20):\n",
    "        name=random.choice(classes)\n",
    "        next_pix=(os.path.join(data_dir,dataset,name))\n",
    "        img = mpimg.imread(os.path.join(next_pix,random.choice(os.listdir(next_pix))))\n",
    "        # Set up subplot; subplot indices start at 1\n",
    "        sp = plt.subplot(nrows, ncols, i + 1)\n",
    "        sp.axis('Off') # Don't show axes (or gridlines)\n",
    "        plt.imshow(img)\n",
    "        plt.title(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Images from Train, Test, and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-14T14:30:27.675207Z",
     "iopub.status.busy": "2023-01-14T14:30:27.674415Z",
     "iopub.status.idle": "2023-01-14T14:30:29.512746Z",
     "shell.execute_reply": "2023-01-14T14:30:29.511475Z",
     "shell.execute_reply.started": "2023-01-14T14:30:27.675170Z"
    },
    "id": "smoCRbh3XNpt",
    "outputId": "3040ee77-9f1e-4c37-9ae2-9f8e236e4a63",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "show_images('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images('valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-14T14:30:31.395158Z",
     "iopub.status.busy": "2023-01-14T14:30:31.393306Z",
     "iopub.status.idle": "2023-01-14T14:30:31.402495Z",
     "shell.execute_reply": "2023-01-14T14:30:31.401594Z",
     "shell.execute_reply.started": "2023-01-14T14:30:31.395126Z"
    },
    "id": "qm_G4vW0XNpu",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# %% Define Function to Calculate Mean and Standard Deviation\n",
    "def get_mean_and_std(dataloader):\n",
    "    channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
    "    for data, _ in dataloader:\n",
    "        # Mean over batch, height and width, but not over the channels\n",
    "        channels_sum += torch.mean(data, dim=[0,2,3])\n",
    "        channels_squared_sum += torch.mean(data**2, dim=[0,2,3])\n",
    "        num_batches += 1\n",
    "    \n",
    "    mean = channels_sum / num_batches\n",
    "\n",
    "    # std = sqrt(E[X^2] - (E[X])^2)\n",
    "    std = (channels_squared_sum / num_batches - mean ** 2) ** 0.5\n",
    "    print(channels_sum,channels_squared_sum,num_batches)\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Calculate Dataset Mean and Std\n",
    "dataset = ImageFolder(data_dir+'/valid', transform=T.ToTensor())\n",
    "dataloader = DataLoader(dataset, batch_size=400)\n",
    "print(get_mean_and_std(dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4qZnof0ycmbS"
   },
   "source": [
    "## Data Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-14T14:30:49.642557Z",
     "iopub.status.busy": "2023-01-14T14:30:49.642244Z",
     "iopub.status.idle": "2023-01-14T14:30:49.652323Z",
     "shell.execute_reply": "2023-01-14T14:30:49.651131Z",
     "shell.execute_reply.started": "2023-01-14T14:30:49.642529Z"
    },
    "id": "e4-LXTBOXNpv",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# %% Define Transformations\n",
    "bird_stats = ([0.4758, 0.4685, 0.3870], [0.2376, 0.2282, 0.2475])\n",
    "\n",
    "train_tfms = T.Compose([\n",
    "    T.RandomCrop(224, padding=4, padding_mode='reflect'),\n",
    "#     T.RandomResizedCrop(256, scale=(0.5,0.9), ratio=(1, 1)), \n",
    "     T.RandomApply(torch.nn.ModuleList([T.GaussianBlur(kernel_size=3,sigma=(0.2, 5))]),p=0.15),\n",
    "    T.RandomHorizontalFlip(), \n",
    "    T.RandomRotation(10),\n",
    "    T.ToTensor(), \n",
    "    T.Normalize(*bird_stats,inplace=True), \n",
    "])\n",
    "\n",
    "valid_tfms = T.Compose([\n",
    "    T.Resize(224), \n",
    "    T.ToTensor(), \n",
    "    T.Normalize(*bird_stats,inplace=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Dataset Class for Bird Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data directory (change this to the correct path)\n",
    "data_dir = \"./100-bird-species\"\n",
    "\n",
    "# Define Custom Dataset Class\n",
    "class BirdDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the original path from the DataFrame\n",
    "        img_path = self.df.iloc[idx]['filepaths']\n",
    "        #print(f\"[DEBUG] Original img_path from DataFrame: {img_path}\")\n",
    "\n",
    "        # Determine the dataset type and prepend \"train/\", \"test/\", or \"valid/\"\n",
    "        if 'train' in img_path:\n",
    "            trimmed_img_path = os.path.join('train', img_path.split('train/')[-1])\n",
    "        elif 'test' in img_path:\n",
    "            trimmed_img_path = os.path.join('test', img_path.split('test/')[-1])\n",
    "        elif 'valid' in img_path:\n",
    "            trimmed_img_path = os.path.join('valid', img_path.split('valid/')[-1])\n",
    "        else:\n",
    "            trimmed_img_path = img_path  # Default in case no match, but ideally, this shouldn't happen\n",
    "\n",
    "        #print(f\"[DEBUG] Trimmed img_path: {trimmed_img_path}\")\n",
    "\n",
    "        # Construct the full path with data_dir\n",
    "        full_img_path = os.path.join(data_dir, trimmed_img_path)\n",
    "        #print(f\"[DEBUG] Full img_path after joining with data_dir: {full_img_path}\")\n",
    "\n",
    "        # Attempt to open the image and handle potential errors\n",
    "        try:\n",
    "            img = Image.open(full_img_path).convert(\"RGB\")\n",
    "            #print(f\"[DEBUG] Successfully opened image: {full_img_path}\")\n",
    "        except FileNotFoundError:\n",
    "            #print(f\"[ERROR] File not found: {full_img_path}\")\n",
    "            raise\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        label = torch.tensor(self.df.iloc[idx]['class id'], dtype=torch.long)\n",
    "        #print(f\"[DEBUG] Image label: {label}\")\n",
    "        return img, label\n",
    "\n",
    "# Splitting DataFrame into train, test, and validation sets\n",
    "paths_df['data set'] = paths_df['filepaths'].apply(\n",
    "    lambda x: 'train' if 'train' in x else ('test' if 'test' in x else 'valid')\n",
    ")\n",
    "#print(f\"[DEBUG] DataFrame after adding 'data set' column:\\n{paths_df.head()}\")\n",
    "\n",
    "train_df = paths_df[paths_df['data set'] == 'train']\n",
    "test_df = paths_df[paths_df['data set'] == 'test']\n",
    "val_df = paths_df[paths_df['data set'] == 'valid']\n",
    "\n",
    "# Create Datasets and DataLoaders\n",
    "train_dataset = BirdDataset(train_df, train_tfms)\n",
    "test_dataset = BirdDataset(test_df, valid_tfms)\n",
    "val_dataset = BirdDataset(val_df, valid_tfms)\n",
    "\n",
    "train_dl = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "test_dl = DataLoader(test_dataset, batch_size=256, shuffle=True, num_workers=3)\n",
    "val_dl = DataLoader(val_dataset, batch_size=70, shuffle=True, num_workers=2)\n",
    "\n",
    "# Debug print for DataLoader lengths\n",
    "#print(f\"[DEBUG] Number of batches in train_dl: {len(train_dl)}\")\n",
    "#print(f\"[DEBUG] Number of batches in test_dl: {len(test_dl)}\")\n",
    "#print(f\"[DEBUG] Number of batches in val_dl: {len(val_dl)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassificationBase(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        acc = accuracy(out, labels)  \n",
    "        return loss,acc\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, train_acc: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}, last_lr: {:.5f}\".format(\n",
    "            epoch+1, result['train_loss'], result['train_accuracy'], result['val_loss'], result['val_acc'], result['lrs'][-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition: ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(in_channels, out_channels, activation=False, pool=False):\n",
    "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
    "              nn.BatchNorm2d(out_channels)]\n",
    "    if activation: layers.append(nn.ReLU(inplace=True))\n",
    "    if pool: layers.append(nn.MaxPool2d(2))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class ResNet34(ImageClassificationBase):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(in_channels, 64, kernel_size=7, stride=1, padding=4),\n",
    "            nn.BatchNorm2d(64),nn.MaxPool2d(2),nn.ReLU(inplace=True))\n",
    "           \n",
    "        self.res1 = nn.Sequential(conv_block(64, 64,activation=True), conv_block(64, 64))\n",
    "        self.res2 = nn.Sequential(conv_block(64, 64,activation=True), conv_block(64, 64))\n",
    "        self.res3 = nn.Sequential(conv_block(64, 64,activation=True), conv_block(64, 64))\n",
    "        self.downsample1=nn.Sequential(conv_block(64, 128,pool=True)) \n",
    "        self.res4 = nn.Sequential(conv_block(64, 128,activation=True, pool=True),\n",
    "                                  conv_block(128,128))\n",
    "        self.res5 = nn.Sequential(conv_block(128, 128,activation=True), conv_block(128, 128))\n",
    "        self.res6 = nn.Sequential(conv_block(128, 128,activation=True), conv_block(128, 128))\n",
    "        self.res7 = nn.Sequential(conv_block(128, 128,activation=True), conv_block(128, 128))\n",
    "        self.res8 = nn.Sequential(conv_block(128, 256,activation=True, pool=True),\n",
    "                                  conv_block(256,256))\n",
    "        self.downsample2 = nn.Sequential(conv_block(128, 256,pool=True))\n",
    "        self.res9 = nn.Sequential(conv_block(256, 256,activation=True), conv_block(256, 256))\n",
    "        self.res10 = nn.Sequential(conv_block(256, 256,activation=True), conv_block(256, 256))\n",
    "        self.res11 = nn.Sequential(conv_block(256, 256,activation=True), conv_block(256, 256))\n",
    "        self.res12 = nn.Sequential(conv_block(256, 256,activation=True), conv_block(256, 256))\n",
    "        self.res13 = nn.Sequential(conv_block(256, 256,activation=True), conv_block(256, 256))\n",
    "        self.res14 = nn.Sequential(conv_block(256, 512,activation=True, pool=True),\n",
    "                                   conv_block(512,512))\n",
    "        \n",
    "        self.downsample3 = nn.Sequential(conv_block(256, 512,pool=True))\n",
    "        self.res15 = nn.Sequential(conv_block(512, 512,activation=True), conv_block(512, 512))\n",
    "        self.res16 = nn.Sequential(conv_block(512, 512,activation=True), conv_block(512, 512,activation=True))\n",
    "\n",
    "        self.classifier = nn.Sequential(nn.AdaptiveMaxPool2d((1,1)), \n",
    "                                        nn.Flatten(), \n",
    "                                        nn.Dropout(0.17),\n",
    "                                        nn.Linear(512, num_classes))\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def init_weights(self,m):\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        out = self.conv1(xb)\n",
    "        out = self.res1(out) + out\n",
    "        out = self.res2(out) + out\n",
    "        out = self.res3(out) + out\n",
    "        out = self.downsample1(out) +self.res4(out)\n",
    "        out = self.res5(out) + out\n",
    "        out = self.res6(out) + out\n",
    "        out = self.res7(out) + out\n",
    "        out = self.downsample2(out) +self.res8(out)\n",
    "        out = self.res9(out) + out\n",
    "        out = self.res10(out) + out\n",
    "        out = self.res11(out) + out\n",
    "        out = self.res12(out) + out\n",
    "        out = self.res13(out) + out\n",
    "        out = self.downsample3(out) + self.res14(out) \n",
    "        out = self.res15(out) + out\n",
    "        out = self.res16(out) + out\n",
    "        out = self.classifier(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the Device available\n",
    "### moving the model and dataset to that device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the Device available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer and loss function\n",
    "model = ResNet34(3, num_classes=len(labels)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Define Training Function\n",
    "train_dl = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0)\n",
    "print(\"[DEBUG] DataLoader created with batch size 64 and num_workers=0\")\n",
    "\n",
    "def train_model(num_epochs, save_path=\"bird_classification_model.pth\"):\n",
    "    print(f\"[INFO] Starting training for {num_epochs} epochs...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0  # Track cumulative loss for the epoch\n",
    "        print(f\"[DEBUG] Epoch {epoch+1} started\")\n",
    "\n",
    "        for batch_idx, (images, labels) in enumerate(train_dl):\n",
    "            print(f\"[DEBUG] Processing batch {batch_idx+1}\")\n",
    "            print(f\"[DEBUG] Batch {batch_idx+1} - images shape: {images.shape}, labels shape: {labels.shape}\")\n",
    "            \n",
    "            # Move data to the appropriate device\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            print(f\"[DEBUG] Batch {batch_idx+1} - images and labels moved to device: {device}\")\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            print(f\"[DEBUG] Batch {batch_idx+1} - outputs shape: {outputs.shape}\")\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "            epoch_loss += loss.item()\n",
    "            print(f\"[DEBUG] Batch {batch_idx+1} - Loss: {loss.item()}\")\n",
    "\n",
    "            # Backward pass and optimization step\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            print(f\"[DEBUG] Batch {batch_idx+1} - Optimizer step completed and gradients zeroed\")\n",
    "\n",
    "        # Average loss for the epoch\n",
    "        avg_loss = epoch_loss / len(train_dl)\n",
    "        print(f\"[INFO] Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss}\")\n",
    "\n",
    "    # Save the trained model\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"[INFO] Model saved to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model and saving it\n",
    "train_model(10, save_path=\"bird_classification_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_dl):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss, val_acc = 0, 0\n",
    "        for images, labels in val_dl:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            val_acc += accuracy(outputs, labels).item()\n",
    "        return val_loss / len(val_dl), val_acc / len(val_dl)\n",
    "\n",
    "# Evaluate on validation data\n",
    "val_loss, val_acc = evaluate(model, val_dl)\n",
    "print(f'Validation Loss: {val_loss}, Validation Accuracy: {val_acc}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
